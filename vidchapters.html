<!DOCTYPE html>
<html lang="en">
<head>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      <link rel='icon' href='img/favicon.ico' type='image/x-icon'/>
      <meta name="description" content="VidChapters-7M: Video Chapters at Scale">
      <meta name="author" content="Antoine Yang">
      <title>VidChapters-7M: Video Chapters at Scale</title>
      <link href="css/bootstrap.min.css" rel="stylesheet">
   </head>
<body>
      <!-- Navigation bar -->
      <div class="navbar navbar-default  navbar-fixed-top bg-info">
        <div class="container">
          <div class="navbar-header">

            <button class="navbar-toggle" type="button" data-toggle="collapse" data-target="#navbar-main">
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
          </div>
          <div class="navbar-collapse collapse" id="navbar-main">

            <ul class="nav navbar-nav navbar-left">
              <li ><a href="http://arxiv.org/abs/2309.13952">Paper</a></li>
              <li ><a href="https://github.com/antoyang/VidChapters"><i class="fab fa-github"></i>Code</a></li>
              <li ><a href="#data">Data</a></li>
              <li ><a href="https://www.youtube.com/watch?v=prn9SP8D5uE&ab_channel=AntoineYang">Video (5 min)</a></li>
            </ul>
          </div>
        </div>
      </div>

      <!-- end of navigation bar -->
      <div style="height:40px;" id="home"></div>
      <div style="height:20px;"></div>

      <div class="container">

         <div class="header">
            <h3>
               <center> <b>VidChapters-7M: Video Chapters at Scale</b> </center>
            </h3>
         </div>
         <div style="height:10px;"></div>

         <center>
            <img id="image" src="img/vidchapters-header.png" width="60%">
         </center>

         <div class="row">
            <h3>Abstract</h3>
            <p style="text-align: justify;">
                Segmenting long videos into chapters enables users to quickly navigate to the information of their interest.
                This important topic has been understudied due to the lack of publicly released datasets.
                To address this issue, we present VidChapters-7M, a dataset of 817K user-chaptered videos including 7M chapters in total.
                VidChapters-7M is automatically created from videos online in a scalable manner by scraping user-annotated chapters and hence without any additional manual annotation.
                We introduce the following three tasks based on this data.
                First, the video chapter generation task consists of temporally segmenting the video and generating a chapter title for each segment.
                To further dissect the problem, we also define two variants of this task: video chapter generation given ground-truth boundaries, which requires generating a chapter title given an annotated video segment, and video chapter grounding, which requires temporally localizing a chapter given its annotated title.
                We benchmark both simple baselines and state-of-the-art video-language models for these three tasks.
                We also show that pretraining on VidChapters-7M transfers well to dense video captioning tasks in both zero-shot and finetuning settings, largely improving the state of the art on the YouCook2 and ViTT benchmarks.
                Finally, our experiments reveal that downstream performance scales well with the size of the pretraining dataset.
            </p>
         </div>

         <div class="row" id="2min">
            <h3>Video: 5 min presentation </h3>
            <center>
               <iframe width="640" height="360" src="https://www.youtube.com/embed/prn9SP8D5uE" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            </center>
         </div>

         <div class="row" id="paper">
            <h3>Paper </h3>
            <ul class="list" style="list-style-type:square">
               <li><a href="http://arxiv.org/abs/2309.13952">arXiv</a></li>
               <li><a href="https://hal.inria.fr/hal-04217697">HAL</a></li>
               <li><a href="https://openreview.net/forum?id=ZknHnDDxng">OpenReview</a></li>
            </ul>

            <h4>BibTeX</h4>
                        <pre><tt>@inproceedings{yang2023vidchapters,
title={VidChapters-7M: Video Chapters at Scale},
author={Antoine Yang and Arsha Nagrani and Ivan Laptev and Josef Sivic and Cordelia Schmid},
booktitle={NeurIPS},
year = {2023}}</tt></pre>
         </div>

         <div class="row" id="code">
            <h3> Code and models </h3>
            <ul class="list" style="list-style-type:square">
               <li><a href="https://github.com/antoyang/VidChapters">GitHub repository </a></li>
               <li><a href="https://drive.google.com/drive/folders/1Gbg_eXtoLE2x1eS_HaA268Hx7cDjodRG?usp=sharing"> Processed data </a></li>
               <li><a href="https://drive.google.com/drive/folders/1mZA-E9c8AJuFMg4v3pf9msggVCGU2U_d?usp=sharing"> Model checkpoints </a></li>
            </ul>
         </div>

         <div class="row" id="data">
            <h3>VidChapters-7M Dataset </h3>
            <ul class="list" style="list-style-type:square">
                <li><a href="https://drive.google.com/file/d/1_U_KwDK2OdEq02jW-VDsbtHLhgKqTnXT/view?usp=sharing"> Annotations </a> </li>
                <li><a href="https://antoineyang.paris.inria.fr/VidChapters/data/AllChapters/asr.pkl"> ASR </a> </li>
                <li><a href="https://drive.google.com/file/d/1kW52N-KULXFdGfjnKK8gz90qdqEGxa6h/view?usp=sharing">Training</a>/<a href="https://drive.google.com/file/d/1tH5WCHfVxK0H8LcQm07ECRLuR47Iu6n4/view?usp=sharing">Validation</a>/<a href="https://drive.google.com/file/d/1hOt3_A6Htme6IMj8AXTRkRDfYDju78bR/view?usp=sharing">Testing</a> video IDs </li>
                <li><a href="https://drive.google.com/file/d/1B0AZ0xHLQhlhq8Mr9O-L0fqKPDCU-_OO/view?usp=sharing"> Tagged video IDs </a> </li>
                <li><a href="https://docs.google.com/forms/d/1ieRsKkalXX0pBFEgCOleTBnHi33PO0wJfRS57-vizB8"> Problematic video removal request form </a> </li>
            </ul>
             <center>
               <figure>
                  <img id="sqa" src="img/vidchapters.png" width="60%">
                  <figcaption>Examples of user-annotated chapters in VidChapters-7M.</figcaption>
               </figure>
            </center>
         </div>

          <div class="row" id="disclaimer">
            <h3>Disclaimer</h3>
            Data sourced from YouTube may be prone to biases.
            Please be careful of unintended societal, gender, racial and other biases when training or deploying models trained on this data.
         </div>

         <div class="row" id="misc">
            <h3> Misc. </h3>
            <ul class="list" style="list-style-type:square">
               <li> <a href="https://neurips.cc/virtual/2023/poster/73545">NeurIPS 2023 paper webpage </a></li>
               <li> <a href="https://antoyang.github.io/slides/vidchapters-neurips-poster.pdf">Poster </a></li>
               <li> <a href="https://antoyang.github.io/slides/vidchapters-neurips.pdf">Slides </a></li>
               </ul>
         </div>

         <div class="row" id="people">
            <h3>People</h3>
            <center>
               <table style="width:80%">
                  <tbody>
                     <tr>
                        <td style="text-align: center; vertical-align: middle;"><a href="https://antoyang.github.io/"><img id="image1" src="img/antoine.jpg" width="60" height="60"> <br> Antoine <br> Yang</a></td>
                        <td style="text-align: center; vertical-align: middle;"><a href="https://a-nagrani.github.io/"><img id="image6" src="img/arsha.jpeg" width="60" height="60"> <br> Arsha <br>Nagrani</a></td>
                        <td style="text-align: center; vertical-align: middle;"><a href="http://www.di.ens.fr/~laptev/"><img id="image4" src="img/ivan.jpg" width="60" height="60"> <br> Ivan <br>Laptev</a></td>
                        <td style="text-align: center; vertical-align: middle;"><a href="http://people.ciirc.cvut.cz/~sivic/"><img id="image3" src="img/josef.jpg" width="60" height="60"> <br>Josef <br>Sivic</a></td>
                        <td style="text-align: center; vertical-align: middle;"><a href="https://www.di.ens.fr/willow/people_webpages/cordelia/"><img id="image5" src="img/cordelia.jpg" width="60" height="60"> <br>Cordelia <br>Schmid</a></td>
                     </tr>
                  </tbody>
               </table>
            </center>
         </div>

          <div class="row" id="acknowledgements">
            <h3>Acknowledgements</h3>
            <p>
                This work was granted access to the HPC resources of IDRIS under the allocation 2023-A0131011670 made by GENCI.
            </p>
            <p>
                The work was funded by Antoine Yang's Google PhD fellowship, the French government under management of Agence Nationale de la Recherche as part of the "Investissements d'avenir" program, reference ANR-19-P3IA-0001 (PRAIRIE 3IA Institute), the Louis Vuitton ENS Chair on Artificial Intelligence, the European Regional Development Fund under project IMPACT (reg.\ no.\ CZ.02.1.01/0.0/0.0/15 003/0000468).
            </p>
            <p>
                We thank Jack Hessel and RÃ©mi Lacroix for helping with forming the dataset, and Antoine Miech for interesting discussions.
            </p>
         </div>

         <div class="row" id="copyright">
            <h3>Copyright Notice</h3>
            <p>The documents contained in these directories are included by the contributing authors as a means to ensure timely dissemination of scholarly and technical work on a non-commercial basis. Copyright and all rights therein are maintained by the authors or by other copyright holders, notwithstanding that they have offered their works here electronically. It is understood that all persons copying this information will adhere to the terms and constraints invoked by each author's copyright.</p>
         </div>
      </div>

      <div class="row">
         <div class="col-md-3 col-sm-12">
            <center>
               <img src="img/inria.png" width="150">
            </center>
         </div>
         <div class="col-md-3 col-sm-12">
            <center>
               <img src="img/ens.png" width="150">
            </center>
         </div>
         <div class="col-md-3 col-sm-12">
            <center>
               <img src="img/ciirc.png" width="120">
            </center>
         </div>
         <div class="col-md-3 col-sm-12">
            <center>
               <img src="img/vgg_logo.png" width="75">
            </center>
         </div>
      </div>
      <!-- /container -->
      <!-- Bootstrap core JavaScript
         ================================================== -->
      <!-- Placed at the end of the document so the pages load faster -->
<script async defer src="https://buttons.github.io/buttons.js"></script>
</body>
</html>
